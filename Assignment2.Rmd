---
title: "Assignment 2"
output: html_notebook
---

## Task1: Simple Linear Regression

1.	Download the file ‘insurance.csv’ from our class Blackboard site.

2.	Read this file into your R environment. Show the step that you used to accomplish this. 
```{r}
insurance.df <- read.csv("insurance.csv", header = T) # load data
dim(insurance.df) # view dimensions
```
3.	Filter the dataframe to create a new dataframe that only contains the records of people who are not smokers.  Show the code that you used to do this.
```{r}
library(dplyr)
non_smokers <- filter(insurance.df, smoker == "no")
dim(non_smokers)
```
-- You will use this new dataframe for the rest of the assignment -- 

4.	Using ggplot, create a scatterplot to depict the relationship between the input variable age and the output variable charges.  Show your scatterplot, along with the code that you used to build it.  What does this scatterplot suggest about the relationship between the two variables?  Why (or why not) does this make intuitive sense to you?
```{r}
library(ggplot2)
ggplot(non_smokers, aes(x = age, y = charges, color = charges)) +
  geom_point() +
  geom_smooth(method = "lm", se=FALSE) +
  scale_color_gradientn(colours = rainbow(3)) +
  theme_classic()
# There is a strong relationship between insurance charges and ages. This makes intuitive sense since the older you become, the more of a deductible/premium you pay on the insurance policy.
```

5.	Find the correlation between age and charges.  Show the code that you used, and the results from your console, in a screenshot.
```{r}
age_charges <- non_smokers[, c(1, 7)]
cor(age_charges) # Correlation table
cor(non_smokers$age, non_smokers$charges, use="complete.obs") # alternative
```

6.	Using your assigned seed value, create a data partition. Assign approximately 60% of the records to your training set, and the other 40% to your validation set. Show the code that you used to do this.
```{r}
sample_size <- floor(0.60 * nrow(non_smokers))
set.seed(180) # set seed for reporducing the partion
train_index <- sample(seq_len(nrow(non_smokers)), size = sample_size)

training <- non_smokers[train_index,]
validation <- non_smokers[-train_index,]
```

7.	Using your training set, create a simple linear regression model, with the input variable age and the outcome variable charges. Show the step(s) that you used to do this.  Include a screenshot of the summary of your model, along with the code you used to generate that summary.
```{r}
insurance_model <- lm(charges~age, data = training)
options(scipen = 999, digits = 0)
summary(insurance_model)
```

8.	What is the regression equation generated by your model? Make up a hypothetical input value and explain what it would predict as an outcome.  To show the predicted outcome value, you can either use a function in R, or just explain what the predicted outcome would be, based on the regression equation and some simple math. 
```{r}
# regression equation -> y = -1877.5 + 263.5x
# if 35 = x, then,
-1877.5 + 263.5 * 35
# for being 35 years old, your charges would be $7,345

```

9.	Using the accuracy() function from the forecast package, assess the accuracy of your model against both the training set and the validation set. What do you notice about these results?  Describe your findings in a couple of sentences.
```{r}
library(forecast)
prediction1 <- predict(insurance_model, training) # predict training
accuracy(prediction1, training$charges)
prediction2 <- predict(insurance_model, validation) # predict validation
accuracy(prediction2, validation$charges)
# With the exception of the ME, the RMSE, MAE, MPE, and MAPE are all within range
# This makes the training and validation set pretty accurate
```


## Task 2: K-Nearest Neighbors

The model that we’ll build will aim to predict which species of fish is being sold at a popular urban fish market, using only the numeric attributes as inputs.  The outcome variable of this model will be Species.  The numeric attributes are described below:

Weight = weight of fish in Gram g

Length1	= vertical length in cm

Length2	= diagonal length in cm

Length3	= cross length in cm

Height = height in cm

Width = diagonal width in cm
     
1.	Download the file ‘fishmarket.csv’ from our class Blackboard site. 

2.	Read this file into your R environment. Show the step that you used to accomplish this.  
```{r}
fishmarket.df <- read.csv("fishmarket.csv", header = T) # load data
dim(fishmarket.df)
```

3.	Using your assigned seed value (from Assignment 2), partition your data into training (60%) and validation (40%) sets. Show the step(s) that you used to do this.
```{r}
library(dplyr)
set.seed(180) # set seed for reporducing the partion
fishmarket <- sample_frac(fishmarket.df, 1)
training <- slice(fishmarket, 1:95) 
validation <- slice(fishmarket, 96:159) 
```

4.	Make up a fake fish (yes, really!)  
a.	Give your fish a name (there’s no R code needed here, and you won’t use the name when you run k-nn...but give the fish a name anyway and just write it here).
```{r}
# balloon_molly
```

b.	Use the runif() function to give your fish values for each of the six numeric attributes.  Use the min and max values from your training set as the lower and upper boundaries for runif().  
```{r}
Weight <- runif(1, min(training$Weight), max(training$Weight))
Lenght1 <- runif(1, min(training$Length1), max(training$Length1))
Lenght2 <- runif(1, min(training$Length2), max(training$Length2))
Lenght3 <- runif(1, min(training$Length3), max(training$Length3))
Height <- runif(1, min(training$Height), max(training$Height))
Width <- runif(1, min(training$Width), max(training$Width))

balloon_molly <- data.frame(Weight = 172, 
                            Length1 = 12, 
                            Length2 = 43, 
                            Length3 = 48, 
                            Height = 10.841, 
                            Width = 7)
```

5.	Normalize your data using the preProcess() function from the caret package. Use Table 7.2 from the book as a guide for this. Show the step(s) that you used to do this.
```{r}
library(caret)
training.norm <- training
validation.norm <- validation
balloon_molly.norm <- balloon_molly

summary(training[, 2:7])

norm.values <- preProcess(training[,2:7], method = c("center", "scale"))
training.norm[, 2:7] <- predict(norm.values, training[, 2:7])
validation.norm[, 2:7] <- predict(norm.values, validation[, 2:7])
balloon_molly.norm[, 1:6] <- predict(norm.values, balloon_molly[, 1:6])


```

6.	Using the knn() function from the FNN package, and using a k-value of 7, generate a predicted classification for your fish. Show the step(s) that you used to do this, along with the output in the console.  What Species was your fish predicted to belong to?  Also, who were your fish’s 7 nearest neighbors?  What Species’ did they belong to?  Show the step(s) that you used to find this out, along with a screenshot of the output in the console.
```{r}
library(FNN)
nn <- knn(train = training.norm[, 2:7], 
          test = balloon_molly.norm[, 1:6], 
          cl = training.norm[, 1], 
          k = 7)
row.names(training)[attr(nn, "nn.index")]
nn
# Per knn, my fish belonged to the 'Bream' species
# Based on the training dataframe, the following neighbors were,
# 8='Whitefish', 68='Perch', 36='Roach', 51:'Perch', 60='Bream', 16='Bream', 80='Bream'
```

7a.  Use your validation set to help you determine an optimal k-value. Use Table 7.3 from the textbook as a guide here. Show the step(s) that you used to do this, along with the output in the console. 
```{r}
accuracy.df <- data.frame(k = seq(1, 95, 1), accuracy = rep(0,95))

for(i in 1:95) {
  knn.pred <- knn(training.norm[, 2:7], 
                  validation.norm[, 2:7], 
                  cl = training.norm[, 1], 
                  k = i)
accuracy.df[i, 2] <- confusionMatrix(knn.pred, validation.norm[, 1])$overall[1]
}
accuracy.df
```

7b.  Using either the base graphics package or ggplot, make a scatterplot with the various k values that you used in 7a on your x-axis, and the accuracy metrics on the y-axis. 
```{r}
library(ggplot2)
ggplot(accuracy.df, aes(x=k, y=accuracy)) + 
  geom_point() + 
  geom_smooth(method = "lm", se=FALSE) + 
  theme_classic()
```

8. Re-run your knn() function with this new k-value. What result did you obtain? Was it different from the one you saw in Step 9? Show the step(s) that you used to do this, along with the output in the console.  Also, what were the outcome classes  (Species) for each of your fish’s k-nearest neighbors?  
```{r}
nn.new <- knn(train = training.norm[, 2:7], 
              test = balloon_molly.norm[, 1:6], 
              cl = training.norm[, 1], 
              k = 3)
nn.new

# The new outcome of new knn is now that 'balloon molly' is classfied as a Perch
# Using K=3 would indicate a new species. However, the index would never change from 1:95.
```

